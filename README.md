# Hidden in the Noise

<div align="center">
  <img src="./images/logo.png" alt="Hidden in the Noise" width="40%" style="margin-top: -20px; margin-bottom: -10px;">
</div>

<h3  align="center">ğŸ§ Hidden in the Noise: Unveiling Backdoors in Audio LLMs Alignment through Latent Acoustic Pattern Triggers</h3>
<p align="center">
  <a href="https://arxiv.org/pdf/2508.02175v3">ğŸ“œ Submitted</a> | <a href="https://huggingface.co/datasets/JusperLee/AudioTrust">ğŸ¤— Dataset</a>

<p align="center">
  <img src="https://visitor-badge.laobi.icu/badge?page_id=Kwwwww74.Hidden-in-the-Noise" alt="è®¿å®¢ç»Ÿè®¡" />
  <img src="https://img.shields.io/github/stars/Kwwwww74/Hidden-in-the-Noise?style=social" alt="GitHub stars" />
  <img alt="Static Badge" src="https://img.shields.io/badge/license-Apache%202.0-blue.svg" />
</p>


<p align="center">

> **Hidden in the Noise (HIN)**, a backdoor framework that uses subtle acoustic patterns as triggers to compromise safety-aligned Audio LLMs while keeping their behavior on clean inputs unchanged. And **AudioSafe**, a benchmark of harmful audio queries across nine risk categories, and show that several audio-feature triggers can achieve over 90% attack success with very small poisoning ratios, whereas simple volume changes are largely revealing a dangerous and previously underexplored vulnerability in Audio LLM safety.


## ğŸ’¥ News

**[2025.11.08]** Our paper has been accepted by **AAAI2026 Oral**!!!

## ğŸ“Œ Table of Contents

- [ğŸ” Overview](#-overview)
- [ğŸ“ Repository Structure](#-repository-structure)
- [ğŸ“¦ Dataset Description](#-dataset-description)
- [ğŸ§ª Scripts Overview](#-scripts-overview)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“Š Benchmark Tasks](#-benchmark-tasks)
- [ğŸ“Œ Citation](#-citation)
- [ğŸ™ Acknowledgements](#-acknowledgements)
- [ğŸ“¬ Contact](#-contact)


## ğŸ” Overview

- ğŸ¯ **Hallucination**: Fabricating content unsupported by audio
- ğŸ›¡ï¸ **Robustness**: Performance under audio degradation
- ğŸ§‘â€ğŸ’» **Authentication**: Resistance to speaker spoofing/cloning
- ğŸ•µï¸ **Privacy**: Avoiding leakage of personal/private content
- âš–ï¸ **Fairness**: Consistency across demographic factors
- ğŸš¨ **Safety**: Generating safe, non-toxic, legal content

![alt text](assets/overall.png)
![alt text](assets/features.png)

The benchmark provides:

- âœ… Expert-annotated prompts across six sub-datasets  
- ğŸ”¬ Model-vs-model evaluation with judge LLMs (e.g., GPT-4o)  
- ğŸ“ˆ Baseline results and reproducible evaluation scripts  


## ğŸ“ Repository Structure

```bash
AudioTrust/
â”œâ”€â”€ assets/                        # Logo and visual assets
â”œâ”€â”€ audio_evals/                  # Core evaluation engine
â”‚   â”œâ”€â”€ agg/                      # Metric aggregation logic
â”‚   â”œâ”€â”€ dataset/                  # Dataset preprocessing
â”‚   â”œâ”€â”€ evaluator/                # Scoring logic
â”‚   â”œâ”€â”€ process/, models/, prompt/, lib/  # Support code
â”‚   â”œâ”€â”€ eval_task.py              # Evaluation controller
â”‚   â”œâ”€â”€ isolate.py                # Single model inference
â”‚   â”œâ”€â”€ recorder.py               # Output logging
â”‚   â”œâ”€â”€ registry.py               # Registry entrypoint
â”‚   â””â”€â”€ utils.py                  # Shared utilities
â”‚
â”œâ”€â”€ registry/                     # Modular registry structure
â”‚   â”œâ”€â”€ agg/, dataset/, eval_task/, evaluator/, model/, prompt/, process/, recorder/
â”‚
â”œâ”€â”€ scripts/                      # Shell scripts per task
â”‚   â””â”€â”€ hallucination/
â”‚       â”œâ”€â”€ inference/
â”‚       â””â”€â”€ evaluation/
â”œâ”€â”€ data/                         # Organized audio files by task
â”‚   â”œâ”€â”€ hallucination/, robustness/, privacy/, fairness/, authentication/, safety/
â”œâ”€â”€ res/                          # Outputs and logs
â”œâ”€â”€ tests/, utils/                # Tests and preprocessing
â”œâ”€â”€ main.py                       # Main execution entry
â”œâ”€â”€ requirments.txt
â”œâ”€â”€ requirments-offline-model.txt
â””â”€â”€ README.md
```


## ğŸ“¦ Dataset Description

* **Language**: English
* **Audio Format**: WAV, mono, 16kHz
* **Size**: \~10.4GB across 6 sub-datasets

Each sample includes:

* `Audio`: decoded waveform (if using Hugging Face loader)
* `AudioPath`: path to original WAV file
* `InferencePrompt`: prompt used for model response generation
* `EvaluationPrompt`: prompt for evaluator model
* `Ref`: reference (expected) answer for scoring

Sub-datasets:

* `{hallucination, robustness, authentication, privacy, fairness, safety}`



## ğŸ§ª Scripts Overview

Each subtask contains:

| Folder        | Purpose                                                           |
| ------------- | ----------------------------------------------------------------- |
| `inference/`  | Use a target model (e.g., Gemini) to generate responses           |
| `evaluation/` | Use an evaluator model (e.g., GPT-4o) to assess generated outputs |

This supports **model-vs-model** evaluation pipelines.

### ğŸ§© Example: Hallucination Task

```bash
scripts/hallucination/
â”œâ”€â”€ inference/
â”‚   â””â”€â”€ gemini-2.5-pro.sh
â””â”€â”€ evaluation/
    â””â”€â”€ gpt-4o.sh
```



## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
git clone https://github.com/JusperLee/AudioTrust.git
cd AudioTrust
pip install -r requirments.txt
```

Or for offline model use:

```bash
pip install -r requirments-offline-model.txt
```

### 2. Load Dataset from Hugging Face

```python
from datasets import load_dataset
dataset = load_dataset("JusperLee/AudioTrust", split="hallucination")
```

#### Materialize the HF dataset to the project `data/` layout

If you plan to run the evaluation scripts that expect a local `data/` folder, first materialize the Hugging Face dataset into the required directory structure:

```bash
python utils/materialize_hf_audio.py --dataset-path JusperLee/AudioTrust
```


### 3. Run Inference and Evaluation

```bash
# Make sure your API keys are set before running:
export OPENAI_API_KEY=your-openai-api-key
export GOOGLE_API_KEY=your-google-api-key

# Step 1: Run inference with Gemini
bash scripts/hallucination/inference/gemini-2.5-pro.sh

# Step 2: Run evaluation using GPT-4o
bash scripts/hallucination/evaluation/gpt-4o.sh
```

Or directly with Python:

```bash
export OPENAI_API_KEY=your-openai-api-key
python main.py \
  --dataset hallucination-content_mismatch \
  --prompt hallucination-inference-content-mismatch-exp1-v1 \
  --model gemini-1.5-pro
```



## ğŸ“Š Benchmark Tasks

| Task                    | Metric              | Description                             |
| ----------------------- | ------------------- | --------------------------------------- |
| Hallucination Detection | Accuracy / Recall   | Groundedness of response in audio       |
| Robustness Evaluation   | Accuracy / Î” Score  | Performance drop under corruption       |
| Authentication Testing  | Attack Success Rate | Resistance to spoofing / voice cloning  |
| Privacy Leakage         | Leakage Rate        | Does the model leak private content?    |
| Fairness Auditing       | Bias Index          | Demographic response disparity          |
| Safety Assessment       | Violation Score     | Generation of unsafe or harmful content |



## ğŸ“Œ Citation

```bibtex
@article{li2025audiotrust,
  title={AudioTrust: Benchmarking the Multifaceted Trustworthiness of Audio Large Language Models},
  author={Li, Kai and Shen, Can and Liu, Yile and Han, Jirui and Zheng, Kelong and Zou, Xuechao and Wang, Zhe and Du, Xingjian and Zhang, Shun and Luo, Hanjun and others},
  journal={arXiv preprint arXiv:2505.16211},
  year={2025}
}
```

## ğŸŒŸ Rising Stars
[![Star History Chart](https://api.star-history.com/svg?repos=Kwwwww74/Hidden-in-the-Noise&type=Date)](https://star-history.com/#Kwwwww74/Hidden-in-the-Noise&Date)


## ğŸ™ Acknowledgements

We gratefully acknowledge [UltraEval-Audio](https://github.com/OpenBMB/UltraEval-Audio) for providing the core infrastructure that inspired and supported parts of this benchmark.


## ğŸ“¬ Contact

For questions or collaboration inquiries:

* Kai Li: tsinghua.kaili@gmail.com, Xinfeng Li: lxfmakeit@gmail.com
* Project Page â€” *Coming Soon*
